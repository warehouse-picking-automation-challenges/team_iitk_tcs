#!/usr/bin/env python

# --------------------------------------------------------
# Faster R-CNN
# Copyright (c) 2015 Microsoft
# Licensed under The MIT License [see LICENSE for details]
# Written by Ross Girshick
# --------------------------------------------------------

"""
Demo script showing detections in sample images.

See README.md for installation instructions before running.
"""
#from "/home/nishant/py-faster-rcnn/tools"

import _init_paths
from fast_rcnn.config import cfg
from fast_rcnn.test import im_detect
from fast_rcnn.nms_wrapper import nms
from utils.timer import Timer
import matplotlib.pyplot as plt
import numpy as np
import scipy.io as sio
import caffe, os, sys, cv2
import argparse


import roslib; roslib.load_manifest('rcnn_object_detection')
# rospy for the subscriber
import rospy
# ROS Image message
from sensor_msgs.msg import Image
# ROS Image message -> OpenCV2 image converter
from cv_bridge import CvBridge, CvBridgeError
# OpenCV2 for saving an image
import cv2
from std_msgs.msg import String,Int32,Int32MultiArray,MultiArrayLayout,MultiArrayDimension,Float64,Float64MultiArray

from rcnn_object_detection.srv import *
#import rcnn_object_detection

#CLASSES = ('__background__',
#           'aeroplane', 'bicycle', 'bird', 'boat',
#           'bottle', 'bus', 'car', 'cat', 'chair',
#           'cow', 'diningtable', 'dog', 'horse',
#           'motorbike', 'person', 'pottedplant',
#           'sheep', 'sofa', 'train', 'tvmonitor')

#CLASSES = ('__background__', # always index 0
#                         'choko','krafty','screw','squeezy')
#CLASSES = ('__background__', # always index 0
#                         'dasani_bottle', 'elmers_school_glue', 'expo_eraser', 'oral_green_toothbrush',
#			 'peva_liner','platinum_bowl','woods_cord')

scores = []
boxes = []

CLASSES = ('__background__', # always index 0
                         'dove_bar', 'rawlings_baseball', 'clorox_brush', 'browns_brush',
			 'dasani_bottle','easter_sippy_cup','cherokee_tshirt','folgers_coffee','crayola_24_ct',
			 'peva_liner','barkely_bones','kygen_puppies',
			 'expo_eraser','scotch_tape','jane_dvd','scotch_mailer','woods_cord','womens_gloves',
			 'cool_glue_sticks','elmers_school_glue','staples_cards','laugh_joke_book','bunny_book',
			 'tissue_box','while_lightbulb','kleenex_towels','jumbo_pencil_cup','pencils',
			 'platinum_bowl','hanes_socks','creativity_stems','fiskars_red','cloud_bear',
			 'safety_plugs','fitness_dumbell','oral_green_toothbrush','glucose_up_botle','command_hooks','oral_red_toothbrush')

NETS = {'vgg16': ('VGG16',
                  'VGG16_faster_rcnn_final.caffemodel'),
        'zf': ('ZF',
                  'ZF_faster_rcnn_final.caffemodel'),
	'apc' : ('APC',
		  'APC_faster_rcnn_final.caffemodel')}

#video = cv2.VideoWriter("/home/nishant/Desktop/rcnn_video.avi",-1,1,(640,480))

# Image service callback
# Service callback for receiving image and object id
# It return the bounding box of the object in the image
def image_service_callback(req):
    print "Inside image service callback"
# Instantiate CvBridge
    bridge = CvBridge()
    try:
        # Convert your ROS Image message to OpenCV2
        cv2_img = bridge.imgmsg_to_cv2(req.input_rgb_img, "bgr8")
    except CvBridgeError, e:
        print(e)
    else:
        # Save your OpenCV2 image as a jpeg
 	print "Nothing"
    #print (req.obj_id.data)
    

    scores = []
    boxes = []
    
    stow_obj_array = req.stow_obj_list.data

    #print len(stow_obj_array)
    for i in stow_obj_array:
	print i

    print "Array assigned "

    #print req.stow_obj_list.data[0],req.stow_obj_list.data[1],req.stow_obj_list.data[2],req.stow_obj_list.data[3]
  
    objScore = 0.0000000
    #objBox,objScore =  demo_ros_stow(net,cv2_img,stow_obj_array)

    obj_rect_corner_list_array = Int32MultiArray(data=[])
    obj_rect_score_array = Float64MultiArray(data=[])    

    first_iteration = False;
    counter = 0
    for i in stow_obj_array:
       objScore = 0.0000000
       objBox = []
       
       objBox,objScore =  demo_ros(net,cv2_img,i,counter)
       counter = counter + 1
       #objBox,objScore =  demo_ros_optimized(net,cv2_img,i)
       print "Bounding box and probability of the object "
       if(len(objBox) == 4):
          #cv2.rectangle(draw_img,(objBox[0],objBox[1]),(objBox[2],objBox[3]),(0,255,0),3)	
          print objBox[0],objBox[1],objBox[2],objBox[3]
          print objScore
          temp_obj_list = [objBox[0],objBox[1],objBox[2],objBox[3]]
          obj_rect_corner_list_array.data.extend(temp_obj_list)
          print "Length of rectangle array"
          print (len(obj_rect_corner_list_array.data)),(len(obj_rect_score_array.data))
          temp_obj_score = objScore
          obj_rect_score_array.data.extend([temp_obj_score])          
       else:
          print "Object box not satisfying minimum probability scores"

    #cv2.putText(cv2_img,CLASSES[req.obj_id.data],(objBox[0],objBox[1]))
    #video.writer(cv2_img)

    for i in range(len(stow_obj_array)):
       cv2.rectangle(cv2_img,(obj_rect_corner_list_array.data[0+4*i],obj_rect_corner_list_array.data[1+4*i]),(obj_rect_corner_list_array.data[2+4*i],obj_rect_corner_list_array.data[3+4*i]),(0,255,0),3)
       cv2.putText(cv2_img,str(stow_obj_array[i]),(int((obj_rect_corner_list_array.data[0+4*i]+obj_rect_corner_list_array.data[2+4*i])/2),int((obj_rect_corner_list_array.data[1+4*i]+obj_rect_corner_list_array.data[3+4*i])/2)),2,2,(0,0,255),2)	
   
   

    cv2.imshow('Object Detected', cv2_img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    
   
    #objBox = []
    return rcnn_object_detection_stowingResponse(obj_rect_corner_list_array,obj_rect_score_array)
    #return rcnn_object_detectionResponse(obj_rect_corner_list,obj_rect_score)     
    
# Image subscriber callback    

def image_callback(msg):
    print("Received an image!")
    # Instantiate CvBridge
    bridge = CvBridge()
    try:
        # Convert your ROS Image message to OpenCV2
        cv2_img = bridge.imgmsg_to_cv2(msg, "bgr8")
    except CvBridgeError, e:
        print "Hurr"
        print(e)
    else:
        # Save your OpenCV2 image as a jpeg
        print "Hurr2"
 	print "Nothing"
       
    #global objBox
    #global objScore
    objBox = []
    objScore = 0.0000000
    objId = 8
    objId = raw_input("Please enter your obj number: ")
    print "You have entered object number "
    
    objBox,objScore =  demo_ros(net, cv2_img,objId)
    #a = demo_ros(net, cv2_img,objId)
    print "Bounding box and probability of the object ", objId
    if(len(objBox) == 4):
       cv2.rectangle(cv2_img,(objBox[0],objBox[1]),(objBox[2],objBox[3]),(0,255,0),3)	
       print objBox[0],objBox[1],objBox[2],objBox[3]
       print objScore
    else:
       print "Object box not satisfying minimum probability scores "


    cv2.imshow('camera_image.jpeg', cv2_img)
    cv2.waitKey(10)
    cv2.destroyAllWindows()   
	#plt.show()

def vis_detections(im, class_name, dets, thresh=0.5):
    """Draw detected bounding boxes."""
    inds = np.where(dets[:, -1] >= thresh)[0]
    if len(inds) == 0:
        return

    im = im[:, :, (2, 1, 0)]
    fig, ax = plt.subplots(figsize=(12, 12))
    ax.imshow(im, aspect='equal')
    for i in inds:
        bbox = dets[i, :4]
        score = dets[i, -1]

        ax.add_patch(
            plt.Rectangle((bbox[0], bbox[1]),
                          bbox[2] - bbox[0],
                          bbox[3] - bbox[1], fill=False,
                          edgecolor='red', linewidth=3.5)
            )
        ax.text(bbox[0], bbox[1] - 2,
                '{:s} {:.3f}'.format(class_name, score),
                bbox=dict(facecolor='blue', alpha=0.5),
                fontsize=14, color='white')

    ax.set_title(('{} detections with '
                  'p({} | box) >= {:.1f}').format(class_name, class_name,
                                                  thresh),
                  fontsize=14)
    plt.axis('off')
    plt.tight_layout()
    plt.draw()

def demo_ros_stow(net, im, stow_obj_arr):
    """Detect object classes in an image using pre-computed object proposals."""

    # Load the demo image
    #im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)
    #im = cv2.imread(im_file)

    # Detect all object classes and regress object bounds
    timer = Timer()
    timer.tic()
    scores, boxes = im_detect(net, im)
    timer.toc()
    print ('Detection took {:.3f}s for '
           '{:d} object proposals').format(timer.total_time, boxes.shape[0])

    #global objBox
    #global objScore
    #print scores
    # Visualize detections for each class
    obj_box = []
    obj_score = 0.00
    CONF_THRESH = 0.00001
    NMS_THRESH = 0.00001
    for cls_ind, cls in enumerate(CLASSES[1:]):
        cls_ind += 1 # because we skipped background
        cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]
        cls_scores = scores[:, cls_ind]
        dets = np.hstack((cls_boxes,
                          cls_scores[:, np.newaxis])).astype(np.float32)
        keep = nms(dets, NMS_THRESH)
        dets = dets[keep, :]
	#print "Box of the class "
	#print dets[0][0],dets[0][1],dets[0][2],dets[0][3]
	#print cls
	#print cls_ind
	#sys.exit(0)
	
	inds = np.where(dets[:, -1] >= CONF_THRESH)[0]
	
	obj_present = False
	# Setting flag true if current cls_ind is present in the stow object list
	for k in stow_obj_arr:
	   if(cls_ind == k):
	      obj_present = True
	      print k,cls_ind 	
	   

	if (obj_present):	  
	   #print "Class indices of object",cls_ind,len(inds) 
	   maxBox = []
	   maxScore = 0.000000000	   
	   for i in inds:
       	      bbox = dets[i, :4]
              score = dets[i, -1]
	      #print i,score	
	      if(score > maxScore):
	         maxScore = score
		 maxBox = bbox
	   
	   if(maxScore > obj_score):
	      obj_box = maxBox
	      obj_score = maxScore
              #print cls_ind,cls
	      #print obj_box[0],obj_box[1],obj_box[2],obj_box[3]
	      #print maxScore
	   #objBox = maxBox
	   #objScore = maxScore
	   
           #break
           #return (obj_box,obj_score)  
	   #print objScore
           #vis_detections(im, cls, dets, thresh=CONF_THRESH)
    
    #print "BEfore return statement"
    return (obj_box,obj_score)       
    #return 1


def demo_ros(net, im,obj_id,count):
    """Detect object classes in an image using pre-computed object proposals."""

    # Load the demo image
    #im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)
    #im = cv2.imread(im_file)

    # Detect all object classes and regress object bounds
    if(count==0):
       timer = Timer()
       timer.tic()
       scores, boxes = im_detect(net, im)
       timer.toc()
       print ('Detection took {:.3f}s for '
              '{:d} object proposals').format(timer.total_time, boxes.shape[0])

    #global objBox
    #global objScore
    #print scores
    # Visualize detections for each class
    obj_box = []
    obj_score = 0.00
    CONF_THRESH = 0.00001
    NMS_THRESH = 0.00001
    for cls_ind, cls in enumerate(CLASSES[1:]):
        cls_ind += 1 # because we skipped background
        cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]
        cls_scores = scores[:, cls_ind]
        dets = np.hstack((cls_boxes,
                          cls_scores[:, np.newaxis])).astype(np.float32)
        keep = nms(dets, NMS_THRESH)
        dets = dets[keep, :]
	#print "Box of the class "
	#print dets[0][0],dets[0][1],dets[0][2],dets[0][3]
	#print cls
	#print cls_ind
	#sys.exit(0)
	
	inds = np.where(dets[:, -1] >= CONF_THRESH)[0]
	if (cls_ind == int(obj_id)):	  
	   #print "Class indices of object",obj_id,cls_ind,len(inds) 
	   maxBox = []
	   maxScore = 0.000000000	   
	   for i in inds:
       	      bbox = dets[i, :4]
              score = dets[i, -1]
	      #print i,score	
	      if(score > maxScore):
	         maxScore = score
		 maxBox = bbox
	   obj_box = maxBox
	   obj_score = maxScore
	   #objBox = maxBox
	   #objScore = maxScore
	   #print cls_ind,cls
	   #print obj_box[0],obj_box[1],obj_box[2],obj_box[3]
	   #print maxScore
           break
           #return (obj_box,obj_score)  
	   #print objScore
           #vis_detections(im, cls, dets, thresh=CONF_THRESH)
    
    print "BEfore return statement"
    return (obj_box,obj_score)       
    #return 1


def demo_ros_optimized(net,cv2_img,obj_id):
    """Detect object classes in an image using pre-computed object proposals."""

    # Load the demo image
    #im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)
    #im = cv2.imread(im_file)

# Detect all object classes and regress object bounds
    timer = Timer()
    timer.tic()
    scores, boxes = im_detect(net, im)
    timer.toc()
    print ('Detection took {:.3f}s for '
           '{:d} object proposals').format(timer.total_time, boxes.shape[0])

    #global objBox
    #global objScore
    #print scores
    # Visualize detections for each class
    obj_box = []
    obj_score = 0.00
    CONF_THRESH = 0.00001
    NMS_THRESH = 0.00001
    for cls_ind, cls in enumerate(CLASSES[1:]):
        cls_ind += 1 # because we skipped background

	#obj_present = False
	# Setting flag true if current cls_ind is present in the stow object list
	#for k in stow_obj_arr:
	#   if(cls_ind == k):
	#      obj_present = True
	#      print k,cls_ind 
	   
	#if(obj_present == False):
	#   continue

	
	if(int(obj_id) != cls_ind):
	   continue
	
	print "Searching for object "
	print cls_ind,obj_id
	
        cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]
        cls_scores = scores[:, cls_ind]
        dets = np.hstack((cls_boxes,
                          cls_scores[:, np.newaxis])).astype(np.float32)
        keep = nms(dets, NMS_THRESH)
        dets = dets[keep, :]
	#print "Box of the class "
	#print dets[0][0],dets[0][1],dets[0][2],dets[0][3]
	#print cls
	#print cls_ind
	#sys.exit(0)
	
	inds = np.where(dets[:, -1] >= CONF_THRESH)[0]
	if (cls_ind == int(obj_id)):	  
	   #print "Class indices of object",obj_id,cls_ind,len(inds) 
	   maxBox = []
	   maxScore = 0.000000000	   
	   for i in inds:
       	      bbox = dets[i, :4]
              score = dets[i, -1]
	      #print i,score	
	      if(score > maxScore):
	         maxScore = score
		 maxBox = bbox
	   obj_box = maxBox
	   obj_score = maxScore
	   #objBox = maxBox
	   #objScore = maxScore
	   #print cls_ind,cls
	   #print obj_box[0],obj_box[1],obj_box[2],obj_box[3]
	   #print maxScore
           break
           #return (obj_box,obj_score)  
	   #print objScore
           #vis_detections(im, cls, dets, thresh=CONF_THRESH)
    
    print "BEfore return statement"
    return (obj_box,obj_score)       
    #return 1

def demo(net, im):
    """Detect object classes in an image using pre-computed object proposals."""

    # Load the demo image
    #im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)
    #im = cv2.imread(im_file)

    # Detect all object classes and regress object bounds
    timer = Timer()
    timer.tic()
    scores, boxes = im_detect(net, im)
    timer.toc()
    print ('Detection took {:.3f}s for '
           '{:d} object proposals').format(timer.total_time, boxes.shape[0])

    #print scores
    # Visualize detections for each class
    CONF_THRESH = 0.001
    NMS_THRESH = 0.0001
    for cls_ind, cls in enumerate(CLASSES[1:]):
        cls_ind += 1 # because we skipped background
        cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]
        cls_scores = scores[:, cls_ind]
        dets = np.hstack((cls_boxes,
                          cls_scores[:, np.newaxis])).astype(np.float32)
        keep = nms(dets, NMS_THRESH)
        dets = dets[keep, :]
	print "Box of the class "
	print dets[0][0],dets[0][1],dets[0][2],dets[0][3]
	print cls
	print cls_ind
	sys.exit(0)
        vis_detections(im, cls, dets, thresh=CONF_THRESH)

def parse_args():
    """Parse input arguments."""
    parser = argparse.ArgumentParser(description='Faster R-CNN demo')
    parser.add_argument('--gpu', dest='gpu_id', help='GPU device id to use [0]',
                        default=0, type=int)
    parser.add_argument('--cpu', dest='cpu_mode',
                        help='Use CPU mode (overrides --gpu)',
                        action='store_true')
    parser.add_argument('--net', dest='demo_net', help='Network to use [vgg16]',
                        choices=NETS.keys(), default='apc')

    args = parser.parse_args()

    return args

if __name__ == '__main__':
    cfg.TEST.HAS_RPN = True  # Use RPN for proposals

    args = parse_args()

   # prototxt = os.path.join(cfg.ROOT_DIR, 'models/pascal_voc', NETS[args.demo_net][0],
    #                        'faster_rcnn_end2end/test.prototxt')
    prototxt = os.path.join(cfg.MODELS_DIR, NETS[args.demo_net][0],
                            'faster_rcnn_alt_opt', 'faster_rcnn_test.pt')
   # prototxt = os.path.join(cfg.MODELS_DIR, NETS[args.demo_net][0],
   #                         'faster_rcnn_end2end', 'solver.prototxt')
   # print (prototxt)	
    caffemodel = os.path.join(cfg.DATA_DIR, 'faster_rcnn_models',
                              NETS[args.demo_net][1])

    if not os.path.isfile(caffemodel):
        raise IOError(('{:s} not found.\nDid you run ./data/script/'
                       'fetch_faster_rcnn_models.sh?').format(caffemodel))

    if args.cpu_mode:
        caffe.set_mode_cpu()
    else:
        caffe.set_mode_gpu()
        caffe.set_device(args.gpu_id)
        cfg.GPU_ID = args.gpu_id
    net = caffe.Net(prototxt, caffemodel, caffe.TEST)

    print '\n\nLoaded network {:s}'.format(caffemodel)

    # Warmup on a dummy image
    im = 128 * np.ones((300, 500, 3), dtype=np.uint8)
    for i in xrange(2):
        _, _= im_detect(net, im)

#    im_names = ['000456.jpg', '000542.jpg', '001150.jpg',
#                '001763.jpg', '004545.jpg']

    print "Before calling service in main"
    rospy.init_node('rcnn_object_detection')
    # Define your image topic
    image_topic = "/usb_cam/image_raw"
    # Set up your subscriber and define its callback
    #sub = rospy.Subscriber(image_topic, Image, image_callback,queue_size = 1,buff_size=2**24)

    # Service for finding object boxes in the image
    object_detect_service = rospy.Service("/rcnn_object_detection_stowing_service",rcnn_object_detection_stowing,image_service_callback)
	
    # Spin until ctrl + c
    rospy.spin()

    #im_names = ['603.jpg','617.jpg']
    #for im_name in im_names:
    #    print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'
    #    print 'Demo for data/demo/{}'.format(im_name)
    #    demo(net, im_name)

    #plt.show()
